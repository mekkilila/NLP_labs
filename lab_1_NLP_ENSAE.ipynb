{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "lab-1-NLP-ENSAE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pvrzu4LZDwo",
        "colab_type": "text"
      },
      "source": [
        "# Lab session 1 \n",
        "# An introduction to textual data\n",
        "\n",
        "## Lecture takeaways \n",
        "\n",
        "- The Why of NLP\n",
        "- What is NLP ? the four challenges of NLP\n",
        "- NLP in three pipelines\n",
        "\n",
        "cf. https://nlp-ensae.github.io/files/NLP-ENSAE-lecture-1.pdf\n",
        "\n",
        "## Lab session Prerequisites\n",
        "\n",
        "- Python \n",
        "- Pandas \n",
        "\n",
        "For those not familiar with pandas https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html \n",
        "\n",
        "## Lab session in a nushell \n",
        "\n",
        "- Grasping a dataset \n",
        "- Basic Tokenization (Word Segmentation) of a dataset\n",
        "(Compute Vocabulary and Zipf's law)\n",
        "- Regex \n",
        "- Hands on some processing tools (POS, NER, ...) \n",
        "\n",
        "## Resources : \n",
        "\n",
        "- NLTK : https://www.nltk.org/api/nltk.tokenize.html \n",
        "- PANDAS : https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html\n",
        "- SPACY : https://spacy.io/usage/spacy-101 \n",
        "\n",
        "\n",
        "## Database\n",
        "\n",
        "We will use the following database:\n",
        "https://d1p17r2m4rzlbo.cloudfront.net/wp-content/uploads/2017/01/PLOS_narrativity.csv.zip\n",
        "\n",
        "This database is used in a scientific article about the importance of narrativity in the citation frequency of climate change scientific articles.  https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0167983  \n",
        "\n",
        "\n",
        "## Tasks\n",
        "\n",
        "### 1. Basic preprocessing\n",
        "#### 1.1 Open the database. Generate simple statistics about the abstracts. How many unique articles are there? What is the mean length of abstracts in characters? \n",
        "#### 1.2 Generate simple statistics about the annotators' data for each article. Do the annotations seem consistent? \n",
        "\n",
        "### 2. Word-level preprocessing\n",
        "#### 2.1 Split the abstracts into list of words. How many different words are there in the vocabulary? \n",
        "#### 2.2 Split the abstracts into list of words using three different tokenizers from nltk. What is the difference in terms of number of words? What do you think has changed?\n",
        "#### 2.3 Check if Zipf's law applies. \n",
        "\n",
        "### 3. Domain specificity and regex\n",
        "#### 3.1 Use regex to retrieve numbers (ints, floats, %, years, ...) using a regex. \n",
        "#### 3.2 How many percent of characters are numbers (as defined above) in a given abstract? \n",
        "#### 3.3 Is there any relationship between the percentage of numbers in an abstract and the amount of citation?  \n",
        "\n",
        "### 4. Classic NLP pipeline\n",
        "#### 4.0 Re-tokenize using spacy\n",
        "#### 4.1 Lemmatize using spacy\n",
        "#### 4.2 POS tagging using spacy, plot the trees\n",
        "#### 4.3 NER using spacy, give the amount of each entity type for a given abstract, and compare it to the amount of citations. \n",
        "\n",
        "### 5. Topic Modelling\n",
        "#### 5.1 Use Gensim's LDA to compute a topic model. \n",
        "#### 5.2 Use PyLDAvis to visualise the topic model. What are the different topic clusters?\n",
        "#### 5.3 Use a tf-idf representation for each abstract, and use your favorite clustering algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jsp-VxWQZDwo",
        "colab_type": "code",
        "outputId": "27b95bfe-b57a-47bf-f5bf-329cffecf582",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Downloading the database\n",
        "!wget https://d1p17r2m4rzlbo.cloudfront.net/wp-content/uploads/2017/01/PLOS_narrativity.csv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-04 14:04:14--  https://d1p17r2m4rzlbo.cloudfront.net/wp-content/uploads/2017/01/PLOS_narrativity.csv.zip\n",
            "Resolving d1p17r2m4rzlbo.cloudfront.net (d1p17r2m4rzlbo.cloudfront.net)... 54.240.168.14, 54.240.168.99, 54.240.168.65, ...\n",
            "Connecting to d1p17r2m4rzlbo.cloudfront.net (d1p17r2m4rzlbo.cloudfront.net)|54.240.168.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 943863 (922K) [application/zip]\n",
            "Saving to: ‘PLOS_narrativity.csv.zip’\n",
            "\n",
            "PLOS_narrativity.cs 100%[===================>] 921.74K  2.08MB/s    in 0.4s    \n",
            "\n",
            "2020-02-04 14:04:15 (2.08 MB/s) - ‘PLOS_narrativity.csv.zip’ saved [943863/943863]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubcnJhB-ZW7M",
        "colab_type": "code",
        "outputId": "6546291a-2913-4809-ec8e-e144346414ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!unzip PLOS_narrativity.csv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  PLOS_narrativity.csv.zip\n",
            "  inflating: PLOS_narrativity.csv    \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._PLOS_narrativity.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Whx0UrMnZ8_I",
        "colab_type": "text"
      },
      "source": [
        "# 1. Basic preprocessing\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9XMO0rukSUI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## 1.1 Open the database. Generate simple statistics about the abstracts. How many unique articles are there? What is the mean length of abstracts in characters?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aDHInXDZivc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQsYiy5ZZqdM",
        "colab_type": "code",
        "outputId": "b3ed9078-ed47-4a17-b6d7-944ddc99c9ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df = pd.read_csv('PLOS_narrativity.csv', index_col=0)\n",
        "print(\"Shape:  {0}\".format(df.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape:  (5614, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_7iPZvdiQ64",
        "colab_type": "code",
        "outputId": "7b92cf77-5b03-48b0-e269-ac7a636c80b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# e.g \n",
        "# Number of different articles in the database"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h_UW9XeigeM",
        "colab_type": "code",
        "outputId": "b54914f5-0308-4808-d5ae-f5c3d430d188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Mean length of abstracts in characters"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1496.1795511221944"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-T5TPTFjJdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Repartition of the abstracts length in characters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIcJZYhYkCa8",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Generate simple statistics about the annotators' data for each article. Do the annotations seem consistent? \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRY93UFskERs",
        "colab_type": "code",
        "outputId": "db03c608-7262-4849-e8ba-97201799d284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# First, number of annotator per article\n",
        "# --> X annotators/article\n",
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['X_unit_id', 'X_created_at', 'X_id', 'X_started_at', 'X_tainted',\n",
              "       'X_channel', 'X_trust', 'X_worker_id', 'X_country', 'X_region',\n",
              "       'X_city', 'X_ip', 'appeal_to_reader', 'conjunctions', 'connectivity',\n",
              "       'narrative_perspective', 'sensory_language', 'setting', 'ab',\n",
              "       'appeal_to_reader_gold', 'conjunctions_gold', 'connectivity_gold',\n",
              "       'narrative_perspective_gold', 'pmid', 'py', 'sensory_language_gold',\n",
              "       'setting_gold', 'so', 'tc', 'af', 'au', 'bp', 'di', 'ep', 'is', 'pd',\n",
              "       'pt', 'sn', 'ti', 'ut', 'vl', 'z9', 'cin_mas', 'firstauthor',\n",
              "       'numberauthors', 'pid_mas', 'title'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdw76Q3WpUrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seing coherence between annotators : need to transform appeal_to_reader, narrative_perspective, setting to bools. \n",
        "# Then, std on the columns. \n",
        "df['appeal_to_reader'] = df.appeal_to_reader.apply(lambda x: True if x==\"yes\" else False)\n",
        "df['narrative_perspective'] = df.narrative_perspective.apply(lambda x: True if x==\"yes\" else False)\n",
        "df['setting'] = df.setting.apply(lambda x: True if x==\"yes\" else False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q9fXWhCt1QI",
        "colab_type": "code",
        "outputId": "8a957b1e-4455-4874-9cd2-09f175550d7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        }
      },
      "source": [
        "eval_cols = [\"appeal_to_reader\", \"conjunctions\", \"connectivity\", \"narrative_perspective\", \"sensory_language\", \"setting\"]\n",
        "df.groupby(df.pmid)[eval_cols].std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>appeal_to_reader</th>\n",
              "      <th>conjunctions</th>\n",
              "      <th>connectivity</th>\n",
              "      <th>narrative_perspective</th>\n",
              "      <th>sensory_language</th>\n",
              "      <th>setting</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pmid</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18726051</th>\n",
              "      <td>0.487950</td>\n",
              "      <td>1.976047</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.487950</td>\n",
              "      <td>1.397276</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18783869</th>\n",
              "      <td>0.534522</td>\n",
              "      <td>1.573592</td>\n",
              "      <td>1.976047</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>1.718249</td>\n",
              "      <td>0.534522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18810525</th>\n",
              "      <td>0.487950</td>\n",
              "      <td>1.345185</td>\n",
              "      <td>1.799471</td>\n",
              "      <td>0.487950</td>\n",
              "      <td>1.463850</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18810526</th>\n",
              "      <td>0.487950</td>\n",
              "      <td>2.214670</td>\n",
              "      <td>0.975900</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>1.214986</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18811616</th>\n",
              "      <td>0.534522</td>\n",
              "      <td>1.069045</td>\n",
              "      <td>1.380131</td>\n",
              "      <td>0.377964</td>\n",
              "      <td>1.069045</td>\n",
              "      <td>0.487950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22216227</th>\n",
              "      <td>0.487950</td>\n",
              "      <td>1.133893</td>\n",
              "      <td>1.718249</td>\n",
              "      <td>0.534522</td>\n",
              "      <td>2.449490</td>\n",
              "      <td>0.377964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22216263</th>\n",
              "      <td>0.487950</td>\n",
              "      <td>0.951190</td>\n",
              "      <td>2.340126</td>\n",
              "      <td>0.487950</td>\n",
              "      <td>0.975900</td>\n",
              "      <td>0.487950</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22216307</th>\n",
              "      <td>0.534522</td>\n",
              "      <td>1.133893</td>\n",
              "      <td>1.799471</td>\n",
              "      <td>0.487950</td>\n",
              "      <td>1.380131</td>\n",
              "      <td>0.377964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22216315</th>\n",
              "      <td>0.534522</td>\n",
              "      <td>1.214986</td>\n",
              "      <td>1.253566</td>\n",
              "      <td>0.487950</td>\n",
              "      <td>1.397276</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22242115</th>\n",
              "      <td>0.534522</td>\n",
              "      <td>1.463850</td>\n",
              "      <td>2.544836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.487950</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>802 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          appeal_to_reader  conjunctions  ...  sensory_language   setting\n",
              "pmid                                      ...                            \n",
              "18726051          0.487950      1.976047  ...          1.397276  0.000000\n",
              "18783869          0.534522      1.573592  ...          1.718249  0.534522\n",
              "18810525          0.487950      1.345185  ...          1.463850  0.000000\n",
              "18810526          0.487950      2.214670  ...          1.214986  0.000000\n",
              "18811616          0.534522      1.069045  ...          1.069045  0.487950\n",
              "...                    ...           ...  ...               ...       ...\n",
              "22216227          0.487950      1.133893  ...          2.449490  0.377964\n",
              "22216263          0.487950      0.951190  ...          0.975900  0.487950\n",
              "22216307          0.534522      1.133893  ...          1.380131  0.377964\n",
              "22216315          0.534522      1.214986  ...          1.397276  0.000000\n",
              "22242115          0.534522      1.463850  ...          0.487950  0.000000\n",
              "\n",
              "[802 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTMJiivwhivd",
        "colab_type": "code",
        "outputId": "6a013da4-8048-4481-cf35-bee33f3fdeaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(df.pmid.unique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "802"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWk_CeIewts0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNv0YjyJ1rhc",
        "colab_type": "text"
      },
      "source": [
        "# 2. Word-level preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTGT_vBp1uA0",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Split the abstracts into list of words. How many different words are there in the vocabulary?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdGlmSrSxqLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import reduce\n",
        "from operator import add\n",
        "\n",
        "# List of words with separator = \" \"\n",
        "arr = df.ab.drop_duplicates().apply(lambda x: x.split(' ')).array\n",
        "\n",
        "arr = reduce(add, arr)\n",
        "#len(set(arr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDphQOEC2pUI",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Split the abstracts into list of words using three different tokenizers from nltk. What is the difference in terms of number of words? What do you think has changed?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n5gotzl2m7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://www.nltk.org/api/nltk.tokenize.html \n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk.tokenize import ToktokTokenizer\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "# e.g : tokenizers = [TreebankWordTokenizer(), ToktokTokenizer(), TweetTokenizer()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkthxY5s5dvA",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 Check if Zipf's law applies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bT4E8Oj5cos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omVMvmwuBvDk",
        "colab_type": "text"
      },
      "source": [
        "# 3. Domain specificity and regex\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQ6pLbSlBxpM",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 Use regex to retrieve numbers (ints, floats, %, years, ...) in abstracts.\n",
        "\n",
        "\n",
        "*Regex cheasheet* : see python's re module documentation https://docs.python.org/3/library/re.html  \n",
        "\n",
        "*Other ressources* : \n",
        "\n",
        "- A good website to write and test regular expressions : \n",
        "https://regex101.com/\n",
        "- A good game to learn regex : https://alf.nu/RegexGolf \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5LP929Xd7IA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "# Regular expression that matches any sequence of numbers:\n",
        "nb =  ''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OscHta8ZBz8E",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 How many percent of characters are numbers (as defined above) in a given abstract?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y-_GUBvB3Ts",
        "colab_type": "text"
      },
      "source": [
        "## 3.3 Is there any relationship between the percentage of numbers in an abstract and the amount of citation?"
      ]
    }
  ]
}